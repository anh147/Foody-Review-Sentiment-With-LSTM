{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMDB Review\nGiven a IMDB movie review, classify it as positive or negative. Basically, it is a sentiment analysis.  \n\nFor doing so, I have used Bidirectional LSTM with Attention for better understanding the context of the review.  \n\nThis notebook is divided into the following sections:\n* Importing the libraries\n* Importing the dataset\n* Text Preprocessing\n* Attention\n* Building the model\n* Training\n* Testing\n***\n### Importing the libraries\nThe cell below is for importing the required libraries and for silencing the warnings","metadata":{}},{"cell_type":"code","source":"# pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:47.255967Z","iopub.execute_input":"2022-12-09T07:18:47.256498Z","iopub.status.idle":"2022-12-09T07:18:47.261163Z","shell.execute_reply.started":"2022-12-09T07:18:47.256439Z","shell.execute_reply":"2022-12-09T07:18:47.259973Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:53:17.700889Z","iopub.execute_input":"2022-12-12T09:53:17.701159Z","iopub.status.idle":"2022-12-12T09:53:39.725073Z","shell.execute_reply.started":"2022-12-12T09:53:17.701100Z","shell.execute_reply":"2022-12-12T09:53:39.724181Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyvi\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/27/27ffee2663f42430cf3434da963f04224fec157b90799fe9e92a3564c1a6/pyvi-0.1.1-py2.py3-none-any.whl (8.5MB)\n\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8.5MB 4.2MB/s eta 0:00:01\n\u001b[?25hCollecting sklearn-crfsuite (from pyvi)\n  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from pyvi) (0.21.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sklearn-crfsuite->pyvi) (1.12.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from sklearn-crfsuite->pyvi) (0.8.3)\nCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/b9/b6f48d74e10136ccfafbadcae751f3e81d143b40847d0f20728026783834/python-crfsuite-0.9.8.tar.gz (440kB)\n\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 440kB 46.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.6/site-packages (from sklearn-crfsuite->pyvi) (4.32.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (0.13.2)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (1.2.1)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (1.16.4)\nBuilding wheels for collected packages: python-crfsuite\n  Building wheel for python-crfsuite (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/fa/ee/3afb15958ad26f3aef88d61c316b4d1af8a97660aa24e6e6d7\nSuccessfully built python-crfsuite\nInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.8 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:52.802820Z","iopub.execute_input":"2022-12-09T07:18:52.803115Z","iopub.status.idle":"2022-12-09T07:18:52.809594Z","shell.execute_reply.started":"2022-12-09T07:18:52.803066Z","shell.execute_reply":"2022-12-09T07:18:52.808403Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re, string, unicodedata\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.pooling import GlobalMaxPooling1D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.layers import *\nfrom keras import backend\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport tensorflow as tf\n\nfrom pyvi import ViTokenizer\nfrom pyvi import ViUtils","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:56:58.992024Z","iopub.execute_input":"2022-12-12T09:56:58.992360Z","iopub.status.idle":"2022-12-12T09:57:01.793633Z","shell.execute_reply.started":"2022-12-12T09:56:58.992301Z","shell.execute_reply":"2022-12-12T09:57:01.792783Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport re\nimport string\nimport codecs","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:57:06.597093Z","iopub.execute_input":"2022-12-12T09:57:06.597466Z","iopub.status.idle":"2022-12-12T09:57:06.602065Z","shell.execute_reply.started":"2022-12-12T09:57:06.597404Z","shell.execute_reply":"2022-12-12T09:57:06.601128Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n#T·ª´ ƒëi·ªÉn t√≠ch c·ª±c, ti√™u c·ª±c, ph·ªß ƒë·ªãnh\npath_nag = '/kaggle/input/sentimentnew/nag.txt'\npath_pos = '/kaggle/input/sentimentnew/pos.txt'\npath_not = '/kaggle/input/sentimentnew/not.txt'\n\nwith codecs.open(path_nag, 'r', encoding='UTF-8') as f:\n    nag = f.readlines()\nnag_list = [n.replace('\\n', '') for n in nag]\n\nwith codecs.open(path_pos, 'r', encoding='UTF-8') as f:\n    pos = f.readlines()\npos_list = [n.replace('\\n', '') for n in pos]\nwith codecs.open(path_not, 'r', encoding='UTF-8') as f:\n    not_ = f.readlines()\nnot_list = [n.replace('\\n', '') for n in not_]\n\n\nVN_CHARS_LOWER = u'·∫°·∫£√£√†√°√¢·∫≠·∫ß·∫•·∫©·∫´ƒÉ·∫Ø·∫±·∫∑·∫≥·∫µ√≥√≤·ªç√µ·ªè√¥·ªô·ªï·ªó·ªì·ªë∆°·ªù·ªõ·ª£·ªü·ª°√©√®·∫ª·∫π·∫Ω√™·∫ø·ªÅ·ªá·ªÉ·ªÖ√∫√π·ª•·ªß≈©∆∞·ª±·ªØ·ª≠·ª´·ª©√≠√¨·ªã·ªâƒ©√Ω·ª≥·ª∑·ªµ·ªπƒë√∞'\nVN_CHARS_UPPER = u'·∫†·∫¢√É√Ä√Å√Ç·∫¨·∫¶·∫§·∫®·∫™ƒÇ·∫Æ·∫∞·∫∂·∫≤·∫¥√ì√í·ªå√ï·ªé√î·ªò·ªî·ªñ·ªí·ªê∆†·ªú·ªö·ª¢·ªû·ª†√â√à·∫∫·∫∏·∫º√ä·∫æ·ªÄ·ªÜ·ªÇ·ªÑ√ö√ô·ª§·ª¶≈®∆Ø·ª∞·ªÆ·ª¨·ª™·ª®√ç√å·ªä·ªàƒ®√ù·ª≤·ª∂·ª¥·ª∏√êƒê'\nVN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:57:09.222048Z","iopub.execute_input":"2022-12-12T09:57:09.222414Z","iopub.status.idle":"2022-12-12T09:57:09.258382Z","shell.execute_reply.started":"2022-12-12T09:57:09.222352Z","shell.execute_reply":"2022-12-12T09:57:09.257319Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Importing the dataset\n***\n\nThe dataset: 'imdb_master.csv' is read and loaded as pandas dataframe.  \nLet's have a look at the data","metadata":{}},{"cell_type":"code","source":"#Importing the dataset\n\ndataset = pd.read_csv('/kaggle/input/dataaaa/data.csv')\ndataset.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-12-12T09:57:11.960148Z","iopub.execute_input":"2022-12-12T09:57:11.960501Z","iopub.status.idle":"2022-12-12T09:57:12.895119Z","shell.execute_reply.started":"2022-12-12T09:57:11.960443Z","shell.execute_reply":"2022-12-12T09:57:12.894361Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Rating\n0  X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...     1.0\n1  G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...     0.0\n2  Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...     1.0\n3  Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...     0.0\n4  ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>X√¥i d·∫ªo, ƒë·ªì ƒÉn ƒë·∫≠m v·ªã. H·ªôp x√¥i ƒë∆∞·ª£c l√≥t l√° tr√¥...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>G·ªçi ship 1 xu·∫•t cari g√† b√°nh naan v√† 3 mi·∫øng g...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Th·ªùi ti·∫øt l·∫°nh nh∆∞ n√†y, c·∫£ nh√† r·ªß nhau ƒë·∫øn leg...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Em c√≥ ƒë·ªçc review th·∫•y mng b·∫£o tr√† s·ªØa n∆∞·ªõng ƒë·ªÅ...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ƒê·ªì ƒÉn r·∫•t ngon, nh√† h√†ng c≈©ng r·∫•t ƒë·∫πp, t·∫•t c·∫£ ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The columns which are not essential are removed.   \nUnlabeled reviews are removed and the class names are converted to numerical digits: 1 for positive and 0 for negative.\nThe dataset is now split into Training set and Test set","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv')\ndata_train = pd.DataFrame({'input':df['Comment'],'label':df['Rating']})\ndata_train = data_train.dropna()\ndata_train = data_train.reset_index(drop=True)\nX_train = data_train['input'].values\ny_train = data_train['label'].values","metadata":{"execution":{"iopub.status.busy":"2022-12-12T10:00:28.925927Z","iopub.execute_input":"2022-12-12T10:00:28.926255Z","iopub.status.idle":"2022-12-12T10:00:29.038401Z","shell.execute_reply.started":"2022-12-12T10:00:28.926186Z","shell.execute_reply":"2022-12-12T10:00:29.037492Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:58:39.923533Z","iopub.execute_input":"2022-12-12T09:58:39.923890Z","iopub.status.idle":"2022-12-12T09:58:39.933647Z","shell.execute_reply.started":"2022-12-12T09:58:39.923840Z","shell.execute_reply":"2022-12-12T09:58:39.932850Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([1., 0., 1., ..., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"plt.hist(y_train,rwidth = 2,align =\"left\")\nplt.savefig('demo.png')","metadata":{"execution":{"iopub.status.busy":"2022-12-12T10:00:32.053359Z","iopub.execute_input":"2022-12-12T10:00:32.053710Z","iopub.status.idle":"2022-12-12T10:00:32.382193Z","shell.execute_reply.started":"2022-12-12T10:00:32.053650Z","shell.execute_reply":"2022-12-12T10:00:32.381062Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# my_data_new = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\n# you could use any filename. We choose submission here\ndata_train.to_excel('my_data_new.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:53.947875Z","iopub.execute_input":"2022-12-09T07:18:53.948446Z","iopub.status.idle":"2022-12-09T07:19:01.843302Z","shell.execute_reply.started":"2022-12-09T07:18:53.948393Z","shell.execute_reply":"2022-12-09T07:19:01.842362Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# X_train","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.844843Z","iopub.execute_input":"2022-12-09T07:19:01.845165Z","iopub.status.idle":"2022-12-09T07:19:01.851567Z","shell.execute_reply.started":"2022-12-09T07:19:01.845117Z","shell.execute_reply":"2022-12-09T07:19:01.850705Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# np.savetxt('data_text.txt', X_train, fmt='%s')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.853115Z","iopub.execute_input":"2022-12-09T07:19:01.853579Z","iopub.status.idle":"2022-12-09T07:19:01.860663Z","shell.execute_reply.started":"2022-12-09T07:19:01.853367Z","shell.execute_reply":"2022-12-09T07:19:01.859787Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train))\nprint(np.shape(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.862036Z","iopub.execute_input":"2022-12-09T07:19:01.862586Z","iopub.status.idle":"2022-12-09T07:19:01.872026Z","shell.execute_reply.started":"2022-12-09T07:19:01.862309Z","shell.execute_reply":"2022-12-09T07:19:01.871033Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"(59070,)\n(59070,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# #Splitting into training and test set\n# dataset = dataset.drop(['Unnamed: 0', 'file'], axis = 1)\n# dataset = dataset[dataset.label != 'unsup']\n# dataset['label'] = dataset['label'].map({'pos': 1, 'neg': 0})\n# dataset_test = dataset[dataset['type'] == 'test']\n# dataset_train = dataset[dataset['type'] == 'train']\n# # X_test = dataset_test.iloc[:, 1:2].values\n# # y_test = dataset_test.iloc[:, 2].values\n# X_train = dataset_train.iloc[:, 1:2].values\n# y_train = dataset_train.iloc[:, 2].values","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.873582Z","iopub.execute_input":"2022-12-09T07:19:01.874170Z","iopub.status.idle":"2022-12-09T07:19:01.881867Z","shell.execute_reply.started":"2022-12-09T07:19:01.873833Z","shell.execute_reply":"2022-12-09T07:19:01.880972Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### Text Preprocessing\n***\nPreprocessing the text so as to have a better data for our model.  \nIt comprises of steps such as removing non-ASCII characters, removing HTML tags, converting to lower-case, lemmatizing.","metadata":{}},{"cell_type":"code","source":"def normalize_text(text):\n\n   #Remove c√°c k√Ω t·ª± k√©o d√†i: vd: ƒë·∫πppppppp\n    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n\n    # Chuy·ªÉn th√†nh ch·ªØ th∆∞·ªùng\n    text = text.lower()\n\n    #Chu·∫©n h√≥a ti·∫øng Vi·ªát, x·ª≠ l√Ω emoj, chu·∫©n h√≥a ti·∫øng Anh, thu·∫≠t ng·ªØ\n    replace_list = {\n        '√≤a': 'o√†', '√≥a': 'o√°', '·ªèa': 'o·∫£', '√µa': 'o√£', '·ªça': 'o·∫°', '√≤e': 'o√®', '√≥e': 'o√©','·ªèe': 'o·∫ª',\n        '√µe': 'o·∫Ω', '·ªçe': 'o·∫π', '√πy': 'u·ª≥', '√∫y': 'u√Ω', '·ªßy': 'u·ª∑', '≈©y': 'u·ªπ','·ª•y': 'u·ªµ', 'u·∫£': '·ªßa',\n        'aÃâ': '·∫£', '√¥ÃÅ': '·ªë', 'u¬¥': '·ªë','√¥ÃÉ': '·ªó', '√¥ÃÄ': '·ªì', '√¥Ãâ': '·ªï', '√¢ÃÅ': '·∫•', '√¢ÃÉ': '·∫´', '√¢Ãâ': '·∫©',\n        '√¢ÃÄ': '·∫ß', 'oÃâ': '·ªè', '√™ÃÄ': '·ªÅ','√™ÃÉ': '·ªÖ', 'ƒÉÃÅ': '·∫Ø', 'uÃâ': '·ªß', '√™ÃÅ': '·∫ø', '∆°Ãâ': '·ªü', 'iÃâ': '·ªâ',\n        'eÃâ': '·∫ª', '√†k': u' √† ','aÀã': '√†', 'iÀã': '√¨', 'ƒÉ¬¥': '·∫Ø','∆∞Ãâ': '·ª≠', 'eÀú': '·∫Ω', 'yÀú': '·ªπ', 'a¬¥': '√°',\n        #Quy c√°c icon v·ªÅ 2 lo·∫°i emoj: T√≠ch c·ª±c ho·∫∑c ti√™u c·ª±c\n        \"üëπ\": \"  t·ªá\", \"üëª\": \" ngon\", \"üíÉ\": \" ngon\",'ü§ô': '  ngon ', 'üëç': '  ngon ',\n        \"üíÑ\": \" ngon\", \"üíé\": \" ngon\", \"üí©\": \" ngon\",\"üòï\": \"  t·ªá\", \"üò±\": \"  t·ªá\", \"üò∏\": \" ngon\",\n        \"üòæ\": \"  t·ªá\", \"üö´\": \"  t·ªá\",  \"ü§¨\": \"  t·ªá\",\"üßö\": \" ngon\", \"üß°\": \" ngon\",'üê∂':'  ngon ',\n        'üëé': '   t·ªá ', 'üò£': '   t·ªá ','‚ú®': '  ngon ', '‚ù£': '  ngon ','‚òÄ': '  ngon ',\n        '‚ô•': '  ngon ', 'ü§©': '  ngon ', 'like': '  ngon ', 'üíå': '  ngon ',\n        'ü§£': '  ngon ', 'üñ§': '  ngon ', 'ü§§': '  ngon ', ':(': '   t·ªá ', 'üò¢': '   t·ªá ',\n        '‚ù§': '  ngon ', 'üòç': '  ngon ', 'üòò': '  ngon ', 'üò™': '   t·ªá ', 'üòä': '  ngon ',\n        '?': ' ? ', 'üòÅ': '  ngon ', 'üíñ': '  ngon ', 'üòü': '   t·ªá ', 'üò≠': '   t·ªá ',\n        'üíØ': '  ngon ', 'üíó': '  ngon ', '‚ô°': '  ngon ', 'üíú': '  ngon ', 'ü§ó': '  ngon ',\n        '^^': '  ngon ', 'üò®': '   t·ªá ', '‚ò∫': '  ngon ', 'üíã': '  ngon ', 'üëå': '  ngon ',\n        'üòñ': '   t·ªá ', 'üòÄ': '  ngon ', ':((': '   t·ªá ', 'üò°': '   t·ªá ', 'üò†': '   t·ªá ',\n        'üòí': '   t·ªá ', 'üôÇ': '  ngon ', 'üòè': '   t·ªá ', 'üòù': '  ngon ', 'üòÑ': '  ngon ',\n        'üòô': '  ngon ', 'üò§': '   t·ªá ', 'üòé': '  ngon ', 'üòÜ': '  ngon ', 'üíö': '  ngon ',\n        '‚úå': '  ngon ', 'üíï': '  ngon ', 'üòû': '   t·ªá ', 'üòì': '   t·ªá ', 'Ô∏èüÜóÔ∏è': '  ngon ',\n        'üòâ': '  ngon ', 'üòÇ': '  ngon ', ':v': '   ngon ', '=))': '   ngon ', 'üòã': '  ngon ',\n        'üíì': '  ngon ', 'üòê': '   t·ªá ', ':3': '  ngon ', 'üò´': '   t·ªá ', 'üò•': '   t·ªá ',\n        'üòÉ': '  ngon ', 'üò¨': ' üò¨ ', 'üòå': ' üòå ', 'üíõ': '  ngon ', 'ü§ù': '  ngon ', 'üéà': '  ngon ',\n        'üòó': '  ngon ', 'ü§î': '   t·ªá ', 'üòë': '   t·ªá ', 'üî•': '   t·ªá ', 'üôè': '   t·ªá ',\n        'üÜó': '  ngon ', 'üòª': '  ngon ', 'üíô': '  ngon ', 'üíü': '  ngon ',\n        'üòö': '  ngon ', '‚ùå': '   t·ªá ', 'üëè': '  ngon ', ';)': '  ngon ', '<3': '  ngon ',\n        'üåù': '  ngon ',  'üå∑': '  ngon ', 'üå∏': '  ngon ', 'üå∫': '  ngon ',\n        'üåº': '  ngon ', 'üçì': '  ngon ', 'üêÖ': '  ngon ', 'üêæ': '  ngon ', 'üëâ': '  ngon ',\n        'üíê': '  ngon ', 'üíû': '  ngon ', 'üí•': '  ngon ', 'üí™': '  ngon ',\n        'üí∞': '  ngon ',  'üòá': '  ngon ', 'üòõ': '  ngon ', 'üòú': '  ngon ',\n        'üôÉ': '  ngon ', 'ü§ë': '  ngon ', 'ü§™': '  ngon ','‚òπ': '   t·ªá ',  'üíÄ': '   t·ªá ',\n        'üòî': '   t·ªá ', 'üòß': '   t·ªá ', 'üò©': '   t·ªá ', 'üò∞': '   t·ªá ', 'üò≥': '   t·ªá ',\n        'üòµ': '   t·ªá ', 'üò∂': '   t·ªá ', 'üôÅ': '   t·ªá ',\n        #Chu·∫©n h√≥a 1 s·ªë sentiment words/English words\n        ':))': '   ngon ', ':)': '  ngon ', '√¥ k√™i': ' ok ', 'okie': ' ok ', ' o k√™ ': ' ok ',\n        'okey': ' ok ', '√¥k√™': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','ok√™':' ok ',\n        ' tks ': u' c√°m ∆°n ', 'thks': u' c√°m ∆°n ', 'thanks': u' c√°m ∆°n ', 'ths': u' c√°m ∆°n ', 'thank': u' c√°m ∆°n ',\n        '‚≠ê': 'star ', '*': 'star ', 'üåü': 'star ', 'üéâ': u'  ngon ',\n        'kg ': u' kh√¥ng ','not': u' kh√¥ng ', u' kg ': u' kh√¥ng ', '\"k ': u' kh√¥ng ',' kh ':u' kh√¥ng ','k√¥':u' kh√¥ng ','hok':u' kh√¥ng ',' kp ': u' kh√¥ng ph·∫£i ',u' k√¥ ': u' kh√¥ng ', '\"ko ': u' kh√¥ng ', u' ko ': u' kh√¥ng ', u' k ': u' kh√¥ng ', 'khong': u' kh√¥ng ', u' hok ': u' kh√¥ng ',\n        'he he': '  ngon ','hehe': '  ngon ','hihi': '  ngon ', 'haha': '  ngon ', 'hjhj': '  ngon ',\n        ' lol ': '   t·ªá ',' cc ': '   t·ªá ','cute': u' d·ªÖ th∆∞∆°ng ','huhu': '   t·ªá ', ' vs ': u' v·ªõi ', 'wa': ' qu√° ', 'w√°': u' qu√°', 'j': u' g√¨ ', '‚Äú': ' ',\n        ' sz ': u' c·ª° ', 'size': u' c·ª° ', u' ƒëx ': u' ƒë∆∞·ª£c ', 'dk': u' ƒë∆∞·ª£c ', 'dc': u' ƒë∆∞·ª£c ', 'ƒëk': u' ƒë∆∞·ª£c ',\n        'ƒëc': u' ƒë∆∞·ª£c ','authentic': u' chu·∫©n ch√≠nh h√£ng ',u' aut ': u' chu·∫©n ch√≠nh h√£ng ', u' auth ': u' chu·∫©n ch√≠nh h√£ng ', 'thick': u'  ngon ', 'store': u' c·ª≠a h√†ng ',\n        'shop': u' c·ª≠a h√†ng ', 'sp': u' s·∫£n ph·∫©m ', 'gud': u' t·ªët ','god': u' t·ªët ','wel done':' t·ªët ', 'good': u' t·ªët ', 'g√∫t': u' t·ªët ',\n        's·∫•u': u' x·∫•u ','gut': u' t·ªët ', u' tot ': u' t·ªët ', u' nice ': u' t·ªët ', 'perfect': 'r·∫•t t·ªët', 'bt': u' b√¨nh th∆∞·ªùng ',\n        'time': u' th·ªùi gian ', 'q√°': u' qu√° ', u' ship ': u' giao h√†ng ', u' m ': u' m√¨nh ', u' mik ': u' m√¨nh ',\n        '√™Ãâ': '·ªÉ', 'product': 's·∫£n ph·∫©m', 'quality': 'ch·∫•t l∆∞·ª£ng','chat':' ch·∫•t ', 'excelent': 'ho√†n h·∫£o', 'bad': 't·ªá','fresh': ' t∆∞∆°i ','sad': ' t·ªá ',\n        'date': u' h·∫°n s·ª≠ d·ª•ng ', 'hsd': u' h·∫°n s·ª≠ d·ª•ng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao h√†ng ',u' s√≠p ': u' giao h√†ng ',\n        'beautiful': u' ƒë·∫πp tuy·ªát v·ªùi ', u' tl ': u' tr·∫£ l·ªùi ', u' r ': u' r·ªìi ', u' shopE ': u' c·ª≠a h√†ng ',u' order ': u' ƒë·∫∑t h√†ng ',\n        'ch·∫•t lg': u' ch·∫•t l∆∞·ª£ng ',u' sd ': u' s·ª≠ d·ª•ng ',u' dt ': u' ƒëi·ªán tho·∫°i ',u' nt ': u' nh·∫Øn tin ',u' tl ': u' tr·∫£ l·ªùi ',u' s√†i ': u' x√†i ',u'bjo':u' bao gi·ªù ',\n        'thik': u' th√≠ch ',u' sop ': u' c·ª≠a h√†ng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' r·∫•t ',u'qu·∫£ ng ':u' qu·∫£ng  ',\n        'dep': u' ƒë·∫πp ',u' xau ': u' x·∫•u ','delicious': u' ngon ', u'h√†g': u' h√†ng ', u'q·ªßa': u' qu·∫£ ',\n        'iu': u' y√™u ','fake': u' gi·∫£ m·∫°o ', 'trl': 'tr·∫£ l·ªùi', '><': u'  ngon ',\n        ' por ': u' t·ªá ',' poor ': u' t·ªá ', 'ib':u' nh·∫Øn tin ', 'rep':u' tr·∫£ l·ªùi ',u'fback':' feedback ','fedback':' feedback ',\n        #d∆∞·ªõi 3* quy v·ªÅ 1*, tr√™n 3* quy v·ªÅ 5*\n        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}\n\n    for k, v in replace_list.items():\n        text = text.replace(k, v)\n\n    # chuyen punctuation th√†nh space\n    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n    text = text.translate(translator)\n\n    text = ViTokenizer.tokenize(text)\n    texts = text.split()\n    len_text = len(texts)\n\n    texts = [t.replace('_', ' ') for t in texts]\n    for i in range(len_text):\n        cp_text = texts[i]\n        if cp_text in not_list: # X·ª≠ l√Ω v·∫•n ƒë·ªÅ ph·ªß ƒë·ªãnh (VD: √°o n√†y ch·∫≥ng ƒë·∫πp--> √°o n√†y notpos)\n            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n\n            for j in range(numb_word):\n                if texts[i + j + 1] in pos_list:\n                    texts[i] = 'kh√¥ng ngon'\n                    texts[i + j + 1] = ''\n\n                if texts[i + j + 1] in nag_list:\n                    texts[i] = 'kh√¥ng t·ªá'\n                    texts[i + j + 1] = ''\n        else: #Th√™m feature cho nh·ªØng sentiment words (√°o n√†y ƒë·∫πp--> √°o n√†y ƒë·∫πp  ngon)\n            if cp_text in pos_list:\n                texts.append(' ngon')\n            elif cp_text in nag_list:\n                texts.append('  t·ªá')\n\n    text = u' '.join(texts)\n\n    #remove n·ªët nh·ªØng k√Ω t·ª± th·ª´a th√£i\n    text = text.replace(u'\"', u' ')\n    text = text.replace(u'Ô∏è', u'')\n    text = text.replace('üèª','')\n\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.883482Z","iopub.execute_input":"2022-12-09T07:19:01.883934Z","iopub.status.idle":"2022-12-09T07:19:01.920812Z","shell.execute_reply.started":"2022-12-09T07:19:01.883745Z","shell.execute_reply":"2022-12-09T07:19:01.920185Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"text =  'd√π ƒÉn_·ªü qu√°n hay order v·ªÅ ƒë·ªÅu m√™ l·ªõm üòç th√≠ch nh·∫•t l√† s·ªët s√¨ d·∫ßu ƒÉn v·ª´a_mi·ªáng s·ªët cay ng·ªçt ƒÉn nhi·ªÅu s·∫Ω h∆°i ng√°n nma v·∫´n c·ª© r·∫•t √¥_k√™ 2 ph·∫ßn g√† m·ªôt ph·∫ßn c∆°m bao no_ƒë·ªß 4 ng∆∞·ªùi nha ƒë√≥ng_g√≥i kƒ© s·∫°ch_s·∫Ω gi√°_th√†nh th√¨ h·ª£p_l√≠ so v·ªõi ch·∫•t_l∆∞·ª£ng ngon h∆°n nhi·ªÅu so v·ªõi nhi·ªÅu qu√°n g√† h√†n qu·ªëc kh√°c n√™n th·ª≠'","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.922305Z","iopub.execute_input":"2022-12-09T07:19:01.922961Z","iopub.status.idle":"2022-12-09T07:19:01.930638Z","shell.execute_reply.started":"2022-12-09T07:19:01.922737Z","shell.execute_reply":"2022-12-09T07:19:01.929897Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"d = [text]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.932021Z","iopub.execute_input":"2022-12-09T07:19:01.932581Z","iopub.status.idle":"2022-12-09T07:19:01.941339Z","shell.execute_reply.started":"2022-12-09T07:19:01.932327Z","shell.execute_reply":"2022-12-09T07:19:01.940640Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"e = [1]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.942890Z","iopub.execute_input":"2022-12-09T07:19:01.943484Z","iopub.status.idle":"2022-12-09T07:19:01.952721Z","shell.execute_reply.started":"2022-12-09T07:19:01.943303Z","shell.execute_reply":"2022-12-09T07:19:01.951915Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"normalize_text(text)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.955809Z","iopub.execute_input":"2022-12-09T07:19:01.956089Z","iopub.status.idle":"2022-12-09T07:19:01.969388Z","shell.execute_reply.started":"2022-12-09T07:19:01.956027Z","shell.execute_reply":"2022-12-09T07:19:01.968544Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'d√π ƒÉn ·ªü qu√°n hay ƒë·∫∑t h√†ng v·ªÅ ƒë·ªÅu m√™ l·ªõm ngon th√≠ch nh·∫•t l√† s·ªët s√¨ d·∫ßu ƒÉn v·ª´a mi·ªáng s·ªët cay ng·ªçt ƒÉn nhi·ªÅu s·∫Ω h∆°i ng√°n nma v·∫´n c·ª© r·∫•t √¥ k√™ 2 ph·∫ßn g√† m·ªôt ph·∫ßn c∆°m bao no ƒë·ªß 4 ng∆∞·ªùi nha ƒë√≥ng g√≥i kƒ© s·∫°ch s·∫Ω gi√° th√†nh th√¨ h·ª£p l√≠ so v·ªõi ch·∫•t l∆∞·ª£ng ngon h∆°n nhi·ªÅu so v·ªõi nhi·ªÅu qu√°n g√† h√†n qu·ªëc kh√°c n√™n th·ª≠  ngon  ngon   t·ªá  ngon  ngon  ngon  ngon  ngon'"},"metadata":{}}]},{"cell_type":"code","source":"#Function for Text Preprocessing\n# stop_words = set(stopwords.words(\"english\")) \n# lemmatizer = WordNetLemmatizer()\n\ndef clean_text(X,y):\n    idx = 0\n    y_train = []\n    processed = []\n    for text in X:\n#         print(text)\n#         text = normalize_text(text)\n#         text = text[0]\n#         text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n#         text = re.sub('<.*?>', '', text)\n#         text = text.lower()\n#         text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n#         text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n#         text = [word for word in text if not word in stop_words]\n        text = list(tf.keras.preprocessing.text.text_to_word_sequence(text))\n        text = \" \".join(text)\n        input_text_pre_no_accent = str(ViUtils.remove_accents(text).decode(\"utf-8\"))\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n#         print(\"vi tokenizer text: \", input_text_pre_accent)\n        input_text_pre_no_accent = ViTokenizer.tokenize(input_text_pre_no_accent)\n        processed.append(input_text_pre_accent)\n        processed.append(input_text_pre_no_accent)\n        y_train.append(y[idx])\n        y_train.append(y[idx])\n#         processed.append(text)\n        idx += 1\n    return processed,y_train","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.970646Z","iopub.execute_input":"2022-12-09T07:19:01.971119Z","iopub.status.idle":"2022-12-09T07:19:01.982188Z","shell.execute_reply.started":"2022-12-09T07:19:01.971069Z","shell.execute_reply":"2022-12-09T07:19:01.981342Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.983659Z","iopub.execute_input":"2022-12-09T07:19:01.985058Z","iopub.status.idle":"2022-12-09T07:19:01.994487Z","shell.execute_reply.started":"2022-12-09T07:19:01.983922Z","shell.execute_reply":"2022-12-09T07:19:01.993730Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Preprocessing the Training Set and Test set","metadata":{}},{"cell_type":"code","source":"X_train_final,y_train = clean_text(X_train,y_train)\n# X_test_final,y_test = clean_text(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.995943Z","iopub.execute_input":"2022-12-09T07:19:01.996393Z","iopub.status.idle":"2022-12-09T07:24:30.739392Z","shell.execute_reply.started":"2022-12-09T07:19:01.996230Z","shell.execute_reply":"2022-12-09T07:24:30.738545Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train_final))\nprint(np.shape(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:30.740885Z","iopub.execute_input":"2022-12-09T07:24:30.741193Z","iopub.status.idle":"2022-12-09T07:24:33.301065Z","shell.execute_reply.started":"2022-12-09T07:24:30.741146Z","shell.execute_reply":"2022-12-09T07:24:33.297511Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"(118140,)\n(118140,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Attention Layer\n***\n\nThe basic concept of attention is that not all words contribute equally to the meaning of a sentence. Hence, their contribution must be weighted.  \nHow attention works is, it basically extracts words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector.","metadata":{}},{"cell_type":"code","source":"# Attention Layer\nclass AttentionWithContext(Layer):\n    \"\"\"\n    Attention operation, with a context/query vector, for temporal data.\n    Supports Masking.\n    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n    \"Hierarchical Attention Networks for Document Classification\"\n    by using a context vector to assist the attention\n    # Input shape\n        3D tensor with shape: `(samples, steps, features)`.\n    # Output shape\n        2D tensor with shape: `(samples, features)`.\n    How to use:\n    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n    The dimensions are inferred based on the output shape of the RNN.\n    Note: The layer has been tested with Keras 2.0.6\n    Example:\n        model.add(LSTM(64, return_sequences=True))\n        model.add(AttentionWithContext())\n        # next add a Dense layer (for classification/regression) or whatever...\n    \"\"\"\n\n    def __init__(self, W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight((input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number Œµ to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n\ndef dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:33.302868Z","iopub.execute_input":"2022-12-09T07:24:33.303451Z","iopub.status.idle":"2022-12-09T07:24:33.323141Z","shell.execute_reply.started":"2022-12-09T07:24:33.303169Z","shell.execute_reply":"2022-12-09T07:24:33.322311Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Some Useful Variables  \n","metadata":{}},{"cell_type":"code","source":"#Tokenization and Padding\nvocab_size = 60000\nmaxlen = 250\nencode_dim = 20\nbatch_size = 32\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train_final)\ntokenized_word_list = tokenizer.texts_to_sequences(X_train_final)\nX_train_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:33.324775Z","iopub.execute_input":"2022-12-09T07:24:33.325226Z","iopub.status.idle":"2022-12-09T07:24:55.700735Z","shell.execute_reply.started":"2022-12-09T07:24:33.325052Z","shell.execute_reply":"2022-12-09T07:24:55.699779Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:55.702114Z","iopub.execute_input":"2022-12-09T07:24:55.702443Z","iopub.status.idle":"2022-12-09T07:24:55.706579Z","shell.execute_reply.started":"2022-12-09T07:24:55.702365Z","shell.execute_reply":"2022-12-09T07:24:55.705555Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train_padded))\nprint(np.shape(X_train_final))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:55.708197Z","iopub.execute_input":"2022-12-09T07:24:55.708683Z","iopub.status.idle":"2022-12-09T07:24:58.247665Z","shell.execute_reply.started":"2022-12-09T07:24:55.708487Z","shell.execute_reply":"2022-12-09T07:24:58.246851Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"(118140, 250)\n(118140,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**EarlyStopping**  \nIt can be used to prevent overfitting.It basically waits a few epochs (5), monitoring the loss for the validation dataset.If the loss doesn't decrease for 2 epochs, it stops the training process.\n\n**ModelCheckpoint**  \nIt is used for saving the best model during training. After each epoch, it takes a look at the Validation accuracy, if it improves globally, this is the best model we have seen till now during the training process and hence, saves it.","metadata":{}},{"cell_type":"code","source":"#EarlyStopping and ModelCheckpoint\n\nes = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n# es = EarlyStopping(monitor = 'val_loss', patience = 6)\nmc = ModelCheckpoint('model_best.h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:58.249059Z","iopub.execute_input":"2022-12-09T07:24:58.249550Z","iopub.status.idle":"2022-12-09T07:24:58.258491Z","shell.execute_reply.started":"2022-12-09T07:24:58.249496Z","shell.execute_reply":"2022-12-09T07:24:58.257860Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model\n***\nThe model used comprises of BiDirectional LSTM with Attention layer on top of it, followed by a dense layer and finally a dense layer with sigmoid activation function to get the sentiment or the class.  \nOptimiser used is ADAM","metadata":{}},{"cell_type":"code","source":"#Building the model\nmodel = Sequential()\nembed = Embedding(input_dim = vocab_size, output_dim = 20, input_length = X_train_padded.shape[1], dropout = 0.4) \nmodel.add(embed)\nmodel.add(Bidirectional(CuDNNLSTM(200, return_sequences = True)))\n\nmodel.add(Dropout(0.3))\nmodel.add(AttentionWithContext())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512))\n# model.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(256))\n# model.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(128))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:58.260241Z","iopub.execute_input":"2022-12-09T07:24:58.260714Z","iopub.status.idle":"2022-12-09T07:25:00.744910Z","shell.execute_reply.started":"2022-12-09T07:24:58.260520Z","shell.execute_reply":"2022-12-09T07:25:00.744165Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 250, 20)           1200000   \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 250, 400)          355200    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 250, 400)          0         \n_________________________________________________________________\nattention_with_context_1 (At (None, 400)               160800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 400)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               205312    \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               32896     \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 2,085,665\nTrainable params: 2,085,665\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training\n***\nSplitting the Training set into Training set and Validation set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_final2, X_val, y_train_final2, y_val = train_test_split(X_train_padded, y_train, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:25:00.748417Z","iopub.execute_input":"2022-12-09T07:25:00.748660Z","iopub.status.idle":"2022-12-09T07:25:00.877987Z","shell.execute_reply.started":"2022-12-09T07:25:00.748613Z","shell.execute_reply":"2022-12-09T07:25:00.877092Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Training the model","metadata":{}},{"cell_type":"code","source":"#Fitting the model\nmodel.fit(X_train_final2, y_train_final2, epochs = 50, batch_size = batch_size, verbose = 1, validation_data = [X_val, y_val], callbacks = [es, mc])\n\n# model.fit(X_train_final2, y_train_final2, epochs = 13, batch_size = batch_size, verbose = 1, validation_data = [X_val, y_val])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:25:00.879444Z","iopub.execute_input":"2022-12-09T07:25:00.879743Z","iopub.status.idle":"2022-12-09T08:15:09.537918Z","shell.execute_reply.started":"2022-12-09T07:25:00.879688Z","shell.execute_reply":"2022-12-09T08:15:09.537027Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Train on 94512 samples, validate on 23628 samples\nEpoch 1/50\n94512/94512 [==============================] - 385s 4ms/step - loss: 0.3427 - acc: 0.8572 - val_loss: 0.3203 - val_acc: 0.8750\n\nEpoch 00001: val_acc improved from -inf to 0.87502, saving model to model_best.h5\nEpoch 2/50\n94512/94512 [==============================] - 375s 4ms/step - loss: 0.2741 - acc: 0.8930 - val_loss: 0.2876 - val_acc: 0.8897\n\nEpoch 00002: val_acc improved from 0.87502 to 0.88966, saving model to model_best.h5\nEpoch 3/50\n94512/94512 [==============================] - 376s 4ms/step - loss: 0.2459 - acc: 0.9048 - val_loss: 0.2671 - val_acc: 0.8949\n\nEpoch 00003: val_acc improved from 0.88966 to 0.89487, saving model to model_best.h5\nEpoch 4/50\n94512/94512 [==============================] - 376s 4ms/step - loss: 0.2200 - acc: 0.9150 - val_loss: 0.2719 - val_acc: 0.8941\n\nEpoch 00004: val_acc did not improve from 0.89487\nEpoch 5/50\n94512/94512 [==============================] - 375s 4ms/step - loss: 0.1988 - acc: 0.9224 - val_loss: 0.2811 - val_acc: 0.8896\n\nEpoch 00005: val_acc did not improve from 0.89487\nEpoch 6/50\n94512/94512 [==============================] - 374s 4ms/step - loss: 0.1792 - acc: 0.9298 - val_loss: 0.2752 - val_acc: 0.8933\n\nEpoch 00006: val_acc did not improve from 0.89487\nEpoch 7/50\n94512/94512 [==============================] - 373s 4ms/step - loss: 0.1624 - acc: 0.9355 - val_loss: 0.3135 - val_acc: 0.8914\n\nEpoch 00007: val_acc did not improve from 0.89487\nEpoch 8/50\n94512/94512 [==============================] - 374s 4ms/step - loss: 0.1468 - acc: 0.9417 - val_loss: 0.3126 - val_acc: 0.8924\n\nEpoch 00008: val_acc did not improve from 0.89487\nEpoch 00008: early stopping\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fd4da6051d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing\n***\nConverting the test data into sequences of integers and padding them.  \nLoading the best model and calculating the accuracy","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\ndata_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\n# data_test = data_test.dropna()\n# data_test = data_test.reset_index(drop=True)\nX_test = data_test['input'].values\n\ndef clean_text_test(X):\n    processed = []\n    for text in X:\n        text = normalize_text(str(text))\n        text = list(tf.keras.preprocessing.text.text_to_word_sequence(str(text)))\n        text = \" \".join(text)\n        input_text_pre_no_accent = str(ViUtils.remove_accents(text).decode(\"utf-8\"))\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n        processed.append(input_text_pre_accent)\n    return processed\n\nX_test_final = clean_text_test(X_test)\n\ntokenized_word_list = tokenizer.texts_to_sequences(X_test_final)\nX_test_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:09.539467Z","iopub.execute_input":"2022-12-09T08:15:09.539766Z","iopub.status.idle":"2022-12-09T08:15:29.411335Z","shell.execute_reply.started":"2022-12-09T08:15:09.539718Z","shell.execute_reply":"2022-12-09T08:15:29.410403Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X_test_final[32]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.416321Z","iopub.execute_input":"2022-12-09T08:15:29.416590Z","iopub.status.idle":"2022-12-09T08:15:29.422915Z","shell.execute_reply.started":"2022-12-09T08:15:29.416543Z","shell.execute_reply":"2022-12-09T08:15:29.422118Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'qu√°n b√© nh∆∞ng v√¥_c√πng ƒë·∫Øt h√†ng nha_t·ªá'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test_final[9])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.424697Z","iopub.execute_input":"2022-12-09T08:15:29.425332Z","iopub.status.idle":"2022-12-09T08:15:29.433130Z","shell.execute_reply.started":"2022-12-09T08:15:29.425281Z","shell.execute_reply":"2022-12-09T08:15:29.432143Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"qu√° tr∆∞a ƒë·ªãnh ƒëi th·ª≠ ph·ªü th√¨n ·ªü l√≤_ƒë√∫c c∆° nh∆∞ng m√† ƒë∆∞·ªùng xa m·ªèi g·ªëi th·∫ø qu√°i n√†o l·∫°i s√† v√†o c√°i qu√°n n√†y g√† t·∫ßn 55k kh√¥ng nh·ªõ 55k hay 65k g√¨ ƒë·∫•y th√™m m√¨ g√≥i tr·∫ßn n∆∞·ªõc s√¥i 10k ƒë∆∞·ª£c c√°i l√† g√†_√°c nh∆∞ng t·∫ßn r·∫•t √≠t v·ªã thu·ªëc ng·∫£i_c·ª©u c≈©ng ch·ªâ ƒë∆∞·ª£c 1 t·∫πo n∆∞·ªõc c≈©ng ch·ªâ ƒë∆∞·ª£c 1 t√≠ c√≥_l·∫Ω v√¨ con g√† ƒë√£ chi·∫øm h·∫øt di·ªán_t√≠ch ·ªëng_b∆° g√† ƒë√£ t·∫ßn s·∫µn ƒë·ªÉ trong ·ªëng_b∆° kh√°ch g·ªçi m·ªõi tr·∫ßn l·∫°i cho √¢m_·∫•m xong ƒë·ªï ra b√°t 1 ƒë·ªëng tr√¥ng r·∫•t m·∫•t c·∫£m_t√¨nh c√°_nh√¢n m√¨nh th·∫•y v·ªã d·ªü v√¥_c√πng d·ªü ngon t·ªá ngon ngon t·ªá t·ªá\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train[3551])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.434763Z","iopub.execute_input":"2022-12-09T08:15:29.435270Z","iopub.status.idle":"2022-12-09T08:15:29.441910Z","shell.execute_reply.started":"2022-12-09T08:15:29.435091Z","shell.execute_reply":"2022-12-09T08:15:29.440793Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Th∆°m, s·∫°ch s·∫Ω\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y_train[3551])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.443393Z","iopub.execute_input":"2022-12-09T08:15:29.443975Z","iopub.status.idle":"2022-12-09T08:15:29.451609Z","shell.execute_reply.started":"2022-12-09T08:15:29.443634Z","shell.execute_reply":"2022-12-09T08:15:29.450309Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[12])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.453106Z","iopub.execute_input":"2022-12-09T08:15:29.453746Z","iopub.status.idle":"2022-12-09T08:15:29.460249Z","shell.execute_reply.started":"2022-12-09T08:15:29.453353Z","shell.execute_reply":"2022-12-09T08:15:29.459340Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"t√¥i v·ª´a ƒë·∫∑t 1 xu·∫•t c∆°m v·ªãt m·∫•t 70 tr√™n now nh∆∞ng c·ª≠a_h√†ng l·∫°i qu√™n kh√¥ng cho v·ªãt v√†o\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[391])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.461877Z","iopub.execute_input":"2022-12-09T08:15:29.462417Z","iopub.status.idle":"2022-12-09T08:15:29.470123Z","shell.execute_reply.started":"2022-12-09T08:15:29.462149Z","shell.execute_reply":"2022-12-09T08:15:29.469090Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"ƒÉn b√°nh_m√¨ ·ªü qu√°n 3 4 l·∫ßn r·ªìi m√† hnay m·ªõi review ƒë∆∞·ª£c ∆∞u_ƒëi·ªÉm ƒë·∫ßu_ti√™n ph·∫£i k·ªÉ ƒë·∫øn l√† gi√°_c·∫£ r·∫•t ok 4k 1 c√°i so v·ªõi m·∫∑t_b·∫±ng chung ·ªü hn l√† h·ª£p_l√Ω r·ªìi th·ª© hai l√† b√°nh ƒÉn r·∫•t th∆°m m√¨nh th√≠ch ƒÉn m·ªÅm m·ªÅm b·∫°n m√¨nh l·∫°i th√≠ch ƒÉn gi√≤n n√™n to√†n mua 5 n·ªç 5 kia pate ngon 1 c√°i b√© b√© xinh_xinh n√™n ƒÉn_kh√¥ng ng√°n th·ª© 3 l√† c√°i xe b√°n b√°nh_m√¨ m√†u r·∫•t ƒë·∫πp ngon v√¨ m√¨nh th√≠ch m√†u v√†ng nh√¨n t·ª´ xa c√°i th·∫•y lu√¥n n·ªïi_b·∫≠t th√¥i r·ªìi nh√¢n_vi√™n b√°n h√†ng nhi·ªát_t√¨nh vui_t√≠nh r·∫•t h√†i_l√≤ng v√¨ d·ªãch_v·ª• t·∫°i qu√°n n√≥i_chung r·∫•t ∆∞ng √† c√≤n c√≥ pate b√°n ngo√†i pate ngon d√£_man c·∫£ nh√† m√¨nh ai c≈©ng khen su·ªët n√™n to√†n ƒë·∫∑t lu√¥n 10 h·ªôp ngon m n n√™n th·ª≠ nh√© ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon t·ªá ngon ngon\n","output_type":"stream"}]},{"cell_type":"code","source":"# y_pred[12]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.471659Z","iopub.execute_input":"2022-12-09T08:15:29.472226Z","iopub.status.idle":"2022-12-09T08:15:29.478188Z","shell.execute_reply.started":"2022-12-09T08:15:29.472049Z","shell.execute_reply":"2022-12-09T08:15:29.477200Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# from tensorflow import keras\nimport keras\n\nmodel = keras.models.load_model('/kaggle/working/model_best.h5', custom_objects={'AttentionWithContext': AttentionWithContext} )\ny_pred = model.predict(X_test_padded)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.479791Z","iopub.execute_input":"2022-12-09T08:15:29.480511Z","iopub.status.idle":"2022-12-09T08:15:37.303129Z","shell.execute_reply.started":"2022-12-09T08:15:29.480238Z","shell.execute_reply":"2022-12-09T08:15:37.302064Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_0912_b.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:16:46.309427Z","iopub.execute_input":"2022-12-09T08:16:46.309786Z","iopub.status.idle":"2022-12-09T08:16:46.346665Z","shell.execute_reply.started":"2022-12-09T08:16:46.309741Z","shell.execute_reply":"2022-12-09T08:16:46.345938Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\n# data_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\n# # data_test = data_test.dropna()\n# # data_test = data_test.reset_index(drop=True)\n# X_test = data_test['input'].values","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:37.359916Z","iopub.execute_input":"2022-12-09T08:15:37.360403Z","iopub.status.idle":"2022-12-09T08:15:37.364129Z","shell.execute_reply.started":"2022-12-09T08:15:37.360350Z","shell.execute_reply":"2022-12-09T08:15:37.363286Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# my_test_data = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103),'input':df['Comment'],  'Rating': np.array(y_pred).reshape(5103)})\n# my_test_data.to_excel('my_test_data_predicted.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:37.365519Z","iopub.execute_input":"2022-12-09T08:15:37.366883Z","iopub.status.idle":"2022-12-09T08:15:37.373212Z","shell.execute_reply.started":"2022-12-09T08:15:37.365925Z","shell.execute_reply":"2022-12-09T08:15:37.372375Z"},"trusted":true},"execution_count":78,"outputs":[]}]}