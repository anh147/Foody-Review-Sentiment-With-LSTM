{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# IMDB Review\nGiven a IMDB movie review, classify it as positive or negative. Basically, it is a sentiment analysis.  \n\nFor doing so, I have used Bidirectional LSTM with Attention for better understanding the context of the review.  \n\nThis notebook is divided into the following sections:\n* Importing the libraries\n* Importing the dataset\n* Text Preprocessing\n* Attention\n* Building the model\n* Training\n* Testing\n***\n### Importing the libraries\nThe cell below is for importing the required libraries and for silencing the warnings","metadata":{}},{"cell_type":"code","source":"# pip install --upgrade pip","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:47.255967Z","iopub.execute_input":"2022-12-09T07:18:47.256498Z","iopub.status.idle":"2022-12-09T07:18:47.261163Z","shell.execute_reply.started":"2022-12-09T07:18:47.256439Z","shell.execute_reply":"2022-12-09T07:18:47.259973Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"!pip install pyvi","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:53:17.700889Z","iopub.execute_input":"2022-12-12T09:53:17.701159Z","iopub.status.idle":"2022-12-12T09:53:39.725073Z","shell.execute_reply.started":"2022-12-12T09:53:17.701100Z","shell.execute_reply":"2022-12-12T09:53:39.724181Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting pyvi\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/27/27ffee2663f42430cf3434da963f04224fec157b90799fe9e92a3564c1a6/pyvi-0.1.1-py2.py3-none-any.whl (8.5MB)\n\u001b[K     |████████████████████████████████| 8.5MB 4.2MB/s eta 0:00:01\n\u001b[?25hCollecting sklearn-crfsuite (from pyvi)\n  Downloading https://files.pythonhosted.org/packages/25/74/5b7befa513482e6dee1f3dd68171a6c9dfc14c0eaa00f885ffeba54fe9b0/sklearn_crfsuite-0.3.6-py2.py3-none-any.whl\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from pyvi) (0.21.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from sklearn-crfsuite->pyvi) (1.12.0)\nRequirement already satisfied: tabulate in /opt/conda/lib/python3.6/site-packages/tabulate-0.8.3-py3.6.egg (from sklearn-crfsuite->pyvi) (0.8.3)\nCollecting python-crfsuite>=0.8.3 (from sklearn-crfsuite->pyvi)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5b/b9/b6f48d74e10136ccfafbadcae751f3e81d143b40847d0f20728026783834/python-crfsuite-0.9.8.tar.gz (440kB)\n\u001b[K     |████████████████████████████████| 440kB 46.5MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: tqdm>=2.0 in /opt/conda/lib/python3.6/site-packages (from sklearn-crfsuite->pyvi) (4.32.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (0.13.2)\nRequirement already satisfied: scipy>=0.17.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (1.2.1)\nRequirement already satisfied: numpy>=1.11.0 in /opt/conda/lib/python3.6/site-packages (from scikit-learn->pyvi) (1.16.4)\nBuilding wheels for collected packages: python-crfsuite\n  Building wheel for python-crfsuite (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/40/fa/ee/3afb15958ad26f3aef88d61c316b4d1af8a97660aa24e6e6d7\nSuccessfully built python-crfsuite\nInstalling collected packages: python-crfsuite, sklearn-crfsuite, pyvi\nSuccessfully installed python-crfsuite-0.9.8 pyvi-0.1.1 sklearn-crfsuite-0.3.6\n","output_type":"stream"}]},{"cell_type":"code","source":"# !pip install keras tensorflow","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:52.802820Z","iopub.execute_input":"2022-12-09T07:18:52.803115Z","iopub.status.idle":"2022-12-09T07:18:52.809594Z","shell.execute_reply.started":"2022-12-09T07:18:52.803066Z","shell.execute_reply":"2022-12-09T07:18:52.808403Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"#Ignoring the warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Importing the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re, string, unicodedata\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers.pooling import GlobalMaxPooling1D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.layers import *\nfrom keras import backend\nfrom sklearn.metrics import f1_score, confusion_matrix\nimport tensorflow as tf\n\nfrom pyvi import ViTokenizer\nfrom pyvi import ViUtils","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:56:58.992024Z","iopub.execute_input":"2022-12-12T09:56:58.992360Z","iopub.status.idle":"2022-12-12T09:57:01.793633Z","shell.execute_reply.started":"2022-12-12T09:56:58.992301Z","shell.execute_reply":"2022-12-12T09:57:01.792783Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"Using TensorFlow backend.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimport re\nimport string\nimport codecs","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:57:06.597093Z","iopub.execute_input":"2022-12-12T09:57:06.597466Z","iopub.status.idle":"2022-12-12T09:57:06.602065Z","shell.execute_reply.started":"2022-12-12T09:57:06.597404Z","shell.execute_reply":"2022-12-12T09:57:06.601128Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\n#Từ điển tích cực, tiêu cực, phủ định\npath_nag = '/kaggle/input/sentimentnew/nag.txt'\npath_pos = '/kaggle/input/sentimentnew/pos.txt'\npath_not = '/kaggle/input/sentimentnew/not.txt'\n\nwith codecs.open(path_nag, 'r', encoding='UTF-8') as f:\n    nag = f.readlines()\nnag_list = [n.replace('\\n', '') for n in nag]\n\nwith codecs.open(path_pos, 'r', encoding='UTF-8') as f:\n    pos = f.readlines()\npos_list = [n.replace('\\n', '') for n in pos]\nwith codecs.open(path_not, 'r', encoding='UTF-8') as f:\n    not_ = f.readlines()\nnot_list = [n.replace('\\n', '') for n in not_]\n\n\nVN_CHARS_LOWER = u'ạảãàáâậầấẩẫăắằặẳẵóòọõỏôộổỗồốơờớợởỡéèẻẹẽêếềệểễúùụủũưựữửừứíìịỉĩýỳỷỵỹđð'\nVN_CHARS_UPPER = u'ẠẢÃÀÁÂẬẦẤẨẪĂẮẰẶẲẴÓÒỌÕỎÔỘỔỖỒỐƠỜỚỢỞỠÉÈẺẸẼÊẾỀỆỂỄÚÙỤỦŨƯỰỮỬỪỨÍÌỊỈĨÝỲỶỴỸÐĐ'\nVN_CHARS = VN_CHARS_LOWER + VN_CHARS_UPPER","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:57:09.222048Z","iopub.execute_input":"2022-12-12T09:57:09.222414Z","iopub.status.idle":"2022-12-12T09:57:09.258382Z","shell.execute_reply.started":"2022-12-12T09:57:09.222352Z","shell.execute_reply":"2022-12-12T09:57:09.257319Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"### Importing the dataset\n***\n\nThe dataset: 'imdb_master.csv' is read and loaded as pandas dataframe.  \nLet's have a look at the data","metadata":{}},{"cell_type":"code","source":"#Importing the dataset\n\ndataset = pd.read_csv('/kaggle/input/dataaaa/data.csv')\ndataset.head()","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2022-12-12T09:57:11.960148Z","iopub.execute_input":"2022-12-12T09:57:11.960501Z","iopub.status.idle":"2022-12-12T09:57:12.895119Z","shell.execute_reply.started":"2022-12-12T09:57:11.960443Z","shell.execute_reply":"2022-12-12T09:57:12.894361Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Rating\n0  Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...     1.0\n1  Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...     0.0\n2  Thời tiết lạnh như này, cả nhà rủ nhau đến leg...     1.0\n3  Em có đọc review thấy mng bảo trà sữa nướng đề...     0.0\n4  Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...     1.0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Xôi dẻo, đồ ăn đậm vị. Hộp xôi được lót lá trô...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Gọi ship 1 xuất cari gà bánh naan và 3 miếng g...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Thời tiết lạnh như này, cả nhà rủ nhau đến leg...</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Em có đọc review thấy mng bảo trà sữa nướng đề...</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Đồ ăn rất ngon, nhà hàng cũng rất đẹp, tất cả ...</td>\n      <td>1.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"The columns which are not essential are removed.   \nUnlabeled reviews are removed and the class names are converted to numerical digits: 1 for positive and 0 for negative.\nThe dataset is now split into Training set and Test set","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/full_train.csv')\ndata_train = pd.DataFrame({'input':df['Comment'],'label':df['Rating']})\ndata_train = data_train.dropna()\ndata_train = data_train.reset_index(drop=True)\nX_train = data_train['input'].values\ny_train = data_train['label'].values","metadata":{"execution":{"iopub.status.busy":"2022-12-12T10:00:28.925927Z","iopub.execute_input":"2022-12-12T10:00:28.926255Z","iopub.status.idle":"2022-12-12T10:00:29.038401Z","shell.execute_reply.started":"2022-12-12T10:00:28.926186Z","shell.execute_reply":"2022-12-12T10:00:29.037492Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-12-12T09:58:39.923533Z","iopub.execute_input":"2022-12-12T09:58:39.923890Z","iopub.status.idle":"2022-12-12T09:58:39.933647Z","shell.execute_reply.started":"2022-12-12T09:58:39.923840Z","shell.execute_reply":"2022-12-12T09:58:39.932850Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([1., 0., 1., ..., 0., 0., 0.])"},"metadata":{}}]},{"cell_type":"code","source":"plt.hist(y_train,rwidth = 2,align =\"left\")\nplt.savefig('demo.png')","metadata":{"execution":{"iopub.status.busy":"2022-12-12T10:00:32.053359Z","iopub.execute_input":"2022-12-12T10:00:32.053710Z","iopub.status.idle":"2022-12-12T10:00:32.382193Z","shell.execute_reply.started":"2022-12-12T10:00:32.053650Z","shell.execute_reply":"2022-12-12T10:00:32.381062Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"# my_data_new = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\n# you could use any filename. We choose submission here\ndata_train.to_excel('my_data_new.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:18:53.947875Z","iopub.execute_input":"2022-12-09T07:18:53.948446Z","iopub.status.idle":"2022-12-09T07:19:01.843302Z","shell.execute_reply.started":"2022-12-09T07:18:53.948393Z","shell.execute_reply":"2022-12-09T07:19:01.842362Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# X_train","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.844843Z","iopub.execute_input":"2022-12-09T07:19:01.845165Z","iopub.status.idle":"2022-12-09T07:19:01.851567Z","shell.execute_reply.started":"2022-12-09T07:19:01.845117Z","shell.execute_reply":"2022-12-09T07:19:01.850705Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"# np.savetxt('data_text.txt', X_train, fmt='%s')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.853115Z","iopub.execute_input":"2022-12-09T07:19:01.853579Z","iopub.status.idle":"2022-12-09T07:19:01.860663Z","shell.execute_reply.started":"2022-12-09T07:19:01.853367Z","shell.execute_reply":"2022-12-09T07:19:01.859787Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train))\nprint(np.shape(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.862036Z","iopub.execute_input":"2022-12-09T07:19:01.862586Z","iopub.status.idle":"2022-12-09T07:19:01.872026Z","shell.execute_reply.started":"2022-12-09T07:19:01.862309Z","shell.execute_reply":"2022-12-09T07:19:01.871033Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"(59070,)\n(59070,)\n","output_type":"stream"}]},{"cell_type":"code","source":"# #Splitting into training and test set\n# dataset = dataset.drop(['Unnamed: 0', 'file'], axis = 1)\n# dataset = dataset[dataset.label != 'unsup']\n# dataset['label'] = dataset['label'].map({'pos': 1, 'neg': 0})\n# dataset_test = dataset[dataset['type'] == 'test']\n# dataset_train = dataset[dataset['type'] == 'train']\n# # X_test = dataset_test.iloc[:, 1:2].values\n# # y_test = dataset_test.iloc[:, 2].values\n# X_train = dataset_train.iloc[:, 1:2].values\n# y_train = dataset_train.iloc[:, 2].values","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.873582Z","iopub.execute_input":"2022-12-09T07:19:01.874170Z","iopub.status.idle":"2022-12-09T07:19:01.881867Z","shell.execute_reply.started":"2022-12-09T07:19:01.873833Z","shell.execute_reply":"2022-12-09T07:19:01.880972Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"markdown","source":"### Text Preprocessing\n***\nPreprocessing the text so as to have a better data for our model.  \nIt comprises of steps such as removing non-ASCII characters, removing HTML tags, converting to lower-case, lemmatizing.","metadata":{}},{"cell_type":"code","source":"def normalize_text(text):\n\n   #Remove các ký tự kéo dài: vd: đẹppppppp\n    text = re.sub(r'([A-Z])\\1+', lambda m: m.group(1).upper(), text, flags=re.IGNORECASE)\n\n    # Chuyển thành chữ thường\n    text = text.lower()\n\n    #Chuẩn hóa tiếng Việt, xử lý emoj, chuẩn hóa tiếng Anh, thuật ngữ\n    replace_list = {\n        'òa': 'oà', 'óa': 'oá', 'ỏa': 'oả', 'õa': 'oã', 'ọa': 'oạ', 'òe': 'oè', 'óe': 'oé','ỏe': 'oẻ',\n        'õe': 'oẽ', 'ọe': 'oẹ', 'ùy': 'uỳ', 'úy': 'uý', 'ủy': 'uỷ', 'ũy': 'uỹ','ụy': 'uỵ', 'uả': 'ủa',\n        'ả': 'ả', 'ố': 'ố', 'u´': 'ố','ỗ': 'ỗ', 'ồ': 'ồ', 'ổ': 'ổ', 'ấ': 'ấ', 'ẫ': 'ẫ', 'ẩ': 'ẩ',\n        'ầ': 'ầ', 'ỏ': 'ỏ', 'ề': 'ề','ễ': 'ễ', 'ắ': 'ắ', 'ủ': 'ủ', 'ế': 'ế', 'ở': 'ở', 'ỉ': 'ỉ',\n        'ẻ': 'ẻ', 'àk': u' à ','aˋ': 'à', 'iˋ': 'ì', 'ă´': 'ắ','ử': 'ử', 'e˜': 'ẽ', 'y˜': 'ỹ', 'a´': 'á',\n        #Quy các icon về 2 loại emoj: Tích cực hoặc tiêu cực\n        \"👹\": \"  tệ\", \"👻\": \" ngon\", \"💃\": \" ngon\",'🤙': '  ngon ', '👍': '  ngon ',\n        \"💄\": \" ngon\", \"💎\": \" ngon\", \"💩\": \" ngon\",\"😕\": \"  tệ\", \"😱\": \"  tệ\", \"😸\": \" ngon\",\n        \"😾\": \"  tệ\", \"🚫\": \"  tệ\",  \"🤬\": \"  tệ\",\"🧚\": \" ngon\", \"🧡\": \" ngon\",'🐶':'  ngon ',\n        '👎': '   tệ ', '😣': '   tệ ','✨': '  ngon ', '❣': '  ngon ','☀': '  ngon ',\n        '♥': '  ngon ', '🤩': '  ngon ', 'like': '  ngon ', '💌': '  ngon ',\n        '🤣': '  ngon ', '🖤': '  ngon ', '🤤': '  ngon ', ':(': '   tệ ', '😢': '   tệ ',\n        '❤': '  ngon ', '😍': '  ngon ', '😘': '  ngon ', '😪': '   tệ ', '😊': '  ngon ',\n        '?': ' ? ', '😁': '  ngon ', '💖': '  ngon ', '😟': '   tệ ', '😭': '   tệ ',\n        '💯': '  ngon ', '💗': '  ngon ', '♡': '  ngon ', '💜': '  ngon ', '🤗': '  ngon ',\n        '^^': '  ngon ', '😨': '   tệ ', '☺': '  ngon ', '💋': '  ngon ', '👌': '  ngon ',\n        '😖': '   tệ ', '😀': '  ngon ', ':((': '   tệ ', '😡': '   tệ ', '😠': '   tệ ',\n        '😒': '   tệ ', '🙂': '  ngon ', '😏': '   tệ ', '😝': '  ngon ', '😄': '  ngon ',\n        '😙': '  ngon ', '😤': '   tệ ', '😎': '  ngon ', '😆': '  ngon ', '💚': '  ngon ',\n        '✌': '  ngon ', '💕': '  ngon ', '😞': '   tệ ', '😓': '   tệ ', '️🆗️': '  ngon ',\n        '😉': '  ngon ', '😂': '  ngon ', ':v': '   ngon ', '=))': '   ngon ', '😋': '  ngon ',\n        '💓': '  ngon ', '😐': '   tệ ', ':3': '  ngon ', '😫': '   tệ ', '😥': '   tệ ',\n        '😃': '  ngon ', '😬': ' 😬 ', '😌': ' 😌 ', '💛': '  ngon ', '🤝': '  ngon ', '🎈': '  ngon ',\n        '😗': '  ngon ', '🤔': '   tệ ', '😑': '   tệ ', '🔥': '   tệ ', '🙏': '   tệ ',\n        '🆗': '  ngon ', '😻': '  ngon ', '💙': '  ngon ', '💟': '  ngon ',\n        '😚': '  ngon ', '❌': '   tệ ', '👏': '  ngon ', ';)': '  ngon ', '<3': '  ngon ',\n        '🌝': '  ngon ',  '🌷': '  ngon ', '🌸': '  ngon ', '🌺': '  ngon ',\n        '🌼': '  ngon ', '🍓': '  ngon ', '🐅': '  ngon ', '🐾': '  ngon ', '👉': '  ngon ',\n        '💐': '  ngon ', '💞': '  ngon ', '💥': '  ngon ', '💪': '  ngon ',\n        '💰': '  ngon ',  '😇': '  ngon ', '😛': '  ngon ', '😜': '  ngon ',\n        '🙃': '  ngon ', '🤑': '  ngon ', '🤪': '  ngon ','☹': '   tệ ',  '💀': '   tệ ',\n        '😔': '   tệ ', '😧': '   tệ ', '😩': '   tệ ', '😰': '   tệ ', '😳': '   tệ ',\n        '😵': '   tệ ', '😶': '   tệ ', '🙁': '   tệ ',\n        #Chuẩn hóa 1 số sentiment words/English words\n        ':))': '   ngon ', ':)': '  ngon ', 'ô kêi': ' ok ', 'okie': ' ok ', ' o kê ': ' ok ',\n        'okey': ' ok ', 'ôkê': ' ok ', 'oki': ' ok ', ' oke ':  ' ok ',' okay':' ok ','okê':' ok ',\n        ' tks ': u' cám ơn ', 'thks': u' cám ơn ', 'thanks': u' cám ơn ', 'ths': u' cám ơn ', 'thank': u' cám ơn ',\n        '⭐': 'star ', '*': 'star ', '🌟': 'star ', '🎉': u'  ngon ',\n        'kg ': u' không ','not': u' không ', u' kg ': u' không ', '\"k ': u' không ',' kh ':u' không ','kô':u' không ','hok':u' không ',' kp ': u' không phải ',u' kô ': u' không ', '\"ko ': u' không ', u' ko ': u' không ', u' k ': u' không ', 'khong': u' không ', u' hok ': u' không ',\n        'he he': '  ngon ','hehe': '  ngon ','hihi': '  ngon ', 'haha': '  ngon ', 'hjhj': '  ngon ',\n        ' lol ': '   tệ ',' cc ': '   tệ ','cute': u' dễ thương ','huhu': '   tệ ', ' vs ': u' với ', 'wa': ' quá ', 'wá': u' quá', 'j': u' gì ', '“': ' ',\n        ' sz ': u' cỡ ', 'size': u' cỡ ', u' đx ': u' được ', 'dk': u' được ', 'dc': u' được ', 'đk': u' được ',\n        'đc': u' được ','authentic': u' chuẩn chính hãng ',u' aut ': u' chuẩn chính hãng ', u' auth ': u' chuẩn chính hãng ', 'thick': u'  ngon ', 'store': u' cửa hàng ',\n        'shop': u' cửa hàng ', 'sp': u' sản phẩm ', 'gud': u' tốt ','god': u' tốt ','wel done':' tốt ', 'good': u' tốt ', 'gút': u' tốt ',\n        'sấu': u' xấu ','gut': u' tốt ', u' tot ': u' tốt ', u' nice ': u' tốt ', 'perfect': 'rất tốt', 'bt': u' bình thường ',\n        'time': u' thời gian ', 'qá': u' quá ', u' ship ': u' giao hàng ', u' m ': u' mình ', u' mik ': u' mình ',\n        'ể': 'ể', 'product': 'sản phẩm', 'quality': 'chất lượng','chat':' chất ', 'excelent': 'hoàn hảo', 'bad': 'tệ','fresh': ' tươi ','sad': ' tệ ',\n        'date': u' hạn sử dụng ', 'hsd': u' hạn sử dụng ','quickly': u' nhanh ', 'quick': u' nhanh ','fast': u' nhanh ','delivery': u' giao hàng ',u' síp ': u' giao hàng ',\n        'beautiful': u' đẹp tuyệt vời ', u' tl ': u' trả lời ', u' r ': u' rồi ', u' shopE ': u' cửa hàng ',u' order ': u' đặt hàng ',\n        'chất lg': u' chất lượng ',u' sd ': u' sử dụng ',u' dt ': u' điện thoại ',u' nt ': u' nhắn tin ',u' tl ': u' trả lời ',u' sài ': u' xài ',u'bjo':u' bao giờ ',\n        'thik': u' thích ',u' sop ': u' cửa hàng ', ' fb ': ' facebook ', ' face ': ' facebook ', ' very ': u' rất ',u'quả ng ':u' quảng  ',\n        'dep': u' đẹp ',u' xau ': u' xấu ','delicious': u' ngon ', u'hàg': u' hàng ', u'qủa': u' quả ',\n        'iu': u' yêu ','fake': u' giả mạo ', 'trl': 'trả lời', '><': u'  ngon ',\n        ' por ': u' tệ ',' poor ': u' tệ ', 'ib':u' nhắn tin ', 'rep':u' trả lời ',u'fback':' feedback ','fedback':' feedback ',\n        #dưới 3* quy về 1*, trên 3* quy về 5*\n        '6 sao': ' 5star ','6 star': ' 5star ', '5star': ' 5star ','5 sao': ' 5star ','5sao': ' 5star ',\n        'starstarstarstarstar': ' 5star ', '1 sao': ' 1star ', '1sao': ' 1star ','2 sao':' 1star ','2sao':' 1star ',\n        '2 starstar':' 1star ','1star': ' 1star ', '0 sao': ' 1star ', '0star': ' 1star ',}\n\n    for k, v in replace_list.items():\n        text = text.replace(k, v)\n\n    # chuyen punctuation thành space\n    translator = str.maketrans(string.punctuation, ' ' * len(string.punctuation))\n    text = text.translate(translator)\n\n    text = ViTokenizer.tokenize(text)\n    texts = text.split()\n    len_text = len(texts)\n\n    texts = [t.replace('_', ' ') for t in texts]\n    for i in range(len_text):\n        cp_text = texts[i]\n        if cp_text in not_list: # Xử lý vấn đề phủ định (VD: áo này chẳng đẹp--> áo này notpos)\n            numb_word = 2 if len_text - i - 1 >= 4 else len_text - i - 1\n\n            for j in range(numb_word):\n                if texts[i + j + 1] in pos_list:\n                    texts[i] = 'không ngon'\n                    texts[i + j + 1] = ''\n\n                if texts[i + j + 1] in nag_list:\n                    texts[i] = 'không tệ'\n                    texts[i + j + 1] = ''\n        else: #Thêm feature cho những sentiment words (áo này đẹp--> áo này đẹp  ngon)\n            if cp_text in pos_list:\n                texts.append(' ngon')\n            elif cp_text in nag_list:\n                texts.append('  tệ')\n\n    text = u' '.join(texts)\n\n    #remove nốt những ký tự thừa thãi\n    text = text.replace(u'\"', u' ')\n    text = text.replace(u'️', u'')\n    text = text.replace('🏻','')\n\n    return text\n","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.883482Z","iopub.execute_input":"2022-12-09T07:19:01.883934Z","iopub.status.idle":"2022-12-09T07:19:01.920812Z","shell.execute_reply.started":"2022-12-09T07:19:01.883745Z","shell.execute_reply":"2022-12-09T07:19:01.920185Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"text =  'dù ăn_ở quán hay order về đều mê lớm 😍 thích nhất là sốt sì dầu ăn vừa_miệng sốt cay ngọt ăn nhiều sẽ hơi ngán nma vẫn cứ rất ô_kê 2 phần gà một phần cơm bao no_đủ 4 người nha đóng_gói kĩ sạch_sẽ giá_thành thì hợp_lí so với chất_lượng ngon hơn nhiều so với nhiều quán gà hàn quốc khác nên thử'","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.922305Z","iopub.execute_input":"2022-12-09T07:19:01.922961Z","iopub.status.idle":"2022-12-09T07:19:01.930638Z","shell.execute_reply.started":"2022-12-09T07:19:01.922737Z","shell.execute_reply":"2022-12-09T07:19:01.929897Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"d = [text]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.932021Z","iopub.execute_input":"2022-12-09T07:19:01.932581Z","iopub.status.idle":"2022-12-09T07:19:01.941339Z","shell.execute_reply.started":"2022-12-09T07:19:01.932327Z","shell.execute_reply":"2022-12-09T07:19:01.940640Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"e = [1]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.942890Z","iopub.execute_input":"2022-12-09T07:19:01.943484Z","iopub.status.idle":"2022-12-09T07:19:01.952721Z","shell.execute_reply.started":"2022-12-09T07:19:01.943303Z","shell.execute_reply":"2022-12-09T07:19:01.951915Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"normalize_text(text)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.955809Z","iopub.execute_input":"2022-12-09T07:19:01.956089Z","iopub.status.idle":"2022-12-09T07:19:01.969388Z","shell.execute_reply.started":"2022-12-09T07:19:01.956027Z","shell.execute_reply":"2022-12-09T07:19:01.968544Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"'dù ăn ở quán hay đặt hàng về đều mê lớm ngon thích nhất là sốt sì dầu ăn vừa miệng sốt cay ngọt ăn nhiều sẽ hơi ngán nma vẫn cứ rất ô kê 2 phần gà một phần cơm bao no đủ 4 người nha đóng gói kĩ sạch sẽ giá thành thì hợp lí so với chất lượng ngon hơn nhiều so với nhiều quán gà hàn quốc khác nên thử  ngon  ngon   tệ  ngon  ngon  ngon  ngon  ngon'"},"metadata":{}}]},{"cell_type":"code","source":"#Function for Text Preprocessing\n# stop_words = set(stopwords.words(\"english\")) \n# lemmatizer = WordNetLemmatizer()\n\ndef clean_text(X,y):\n    idx = 0\n    y_train = []\n    processed = []\n    for text in X:\n#         print(text)\n#         text = normalize_text(text)\n#         text = text[0]\n#         text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n#         text = re.sub('<.*?>', '', text)\n#         text = text.lower()\n#         text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n#         text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n#         text = [word for word in text if not word in stop_words]\n        text = list(tf.keras.preprocessing.text.text_to_word_sequence(text))\n        text = \" \".join(text)\n        input_text_pre_no_accent = str(ViUtils.remove_accents(text).decode(\"utf-8\"))\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n#         print(\"vi tokenizer text: \", input_text_pre_accent)\n        input_text_pre_no_accent = ViTokenizer.tokenize(input_text_pre_no_accent)\n        processed.append(input_text_pre_accent)\n        processed.append(input_text_pre_no_accent)\n        y_train.append(y[idx])\n        y_train.append(y[idx])\n#         processed.append(text)\n        idx += 1\n    return processed,y_train","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.970646Z","iopub.execute_input":"2022-12-09T07:19:01.971119Z","iopub.status.idle":"2022-12-09T07:19:01.982188Z","shell.execute_reply.started":"2022-12-09T07:19:01.971069Z","shell.execute_reply":"2022-12-09T07:19:01.981342Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.983659Z","iopub.execute_input":"2022-12-09T07:19:01.985058Z","iopub.status.idle":"2022-12-09T07:19:01.994487Z","shell.execute_reply.started":"2022-12-09T07:19:01.983922Z","shell.execute_reply":"2022-12-09T07:19:01.993730Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Preprocessing the Training Set and Test set","metadata":{}},{"cell_type":"code","source":"X_train_final,y_train = clean_text(X_train,y_train)\n# X_test_final,y_test = clean_text(X_test,y_test)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:19:01.995943Z","iopub.execute_input":"2022-12-09T07:19:01.996393Z","iopub.status.idle":"2022-12-09T07:24:30.739392Z","shell.execute_reply.started":"2022-12-09T07:19:01.996230Z","shell.execute_reply":"2022-12-09T07:24:30.738545Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train_final))\nprint(np.shape(y_train))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:30.740885Z","iopub.execute_input":"2022-12-09T07:24:30.741193Z","iopub.status.idle":"2022-12-09T07:24:33.301065Z","shell.execute_reply.started":"2022-12-09T07:24:30.741146Z","shell.execute_reply":"2022-12-09T07:24:33.297511Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"(118140,)\n(118140,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Attention Layer\n***\n\nThe basic concept of attention is that not all words contribute equally to the meaning of a sentence. Hence, their contribution must be weighted.  \nHow attention works is, it basically extracts words that are important to the meaning of the sentence and aggregate the representation of those informative words to form a sentence vector.","metadata":{}},{"cell_type":"code","source":"# Attention Layer\nclass AttentionWithContext(Layer):\n    \"\"\"\n    Attention operation, with a context/query vector, for temporal data.\n    Supports Masking.\n    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n    \"Hierarchical Attention Networks for Document Classification\"\n    by using a context vector to assist the attention\n    # Input shape\n        3D tensor with shape: `(samples, steps, features)`.\n    # Output shape\n        2D tensor with shape: `(samples, features)`.\n    How to use:\n    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n    The dimensions are inferred based on the output shape of the RNN.\n    Note: The layer has been tested with Keras 2.0.6\n    Example:\n        model.add(LSTM(64, return_sequences=True))\n        model.add(AttentionWithContext())\n        # next add a Dense layer (for classification/regression) or whatever...\n    \"\"\"\n\n    def __init__(self, W_regularizer=None, u_regularizer=None, b_regularizer=None,\n                 W_constraint=None, u_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.u_regularizer = regularizers.get(u_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.u_constraint = constraints.get(u_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        super(AttentionWithContext, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        if self.bias:\n            self.b = self.add_weight((input_shape[-1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n\n        self.u = self.add_weight((input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_u'.format(self.name),\n                                 regularizer=self.u_regularizer,\n                                 constraint=self.u_constraint)\n\n        super(AttentionWithContext, self).build(input_shape)\n\n    def compute_mask(self, input, input_mask=None):\n        # do not pass the mask to the next layers\n        return None\n\n    def call(self, x, mask=None):\n        uit = dot_product(x, self.W)\n\n        if self.bias:\n            uit += self.b\n\n        uit = K.tanh(uit)\n        ait = dot_product(uit, self.u)\n\n        a = K.exp(ait)\n\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # Cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx())\n\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n\n        a = K.expand_dims(a)\n        weighted_input = x * a\n        return K.sum(weighted_input, axis=1)\n\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], input_shape[-1]\n\ndef dot_product(x, kernel):\n    \"\"\"\n    Wrapper for dot product operation, in order to be compatible with both\n    Theano and Tensorflow\n    Args:\n        x (): input\n        kernel (): weights\n    Returns:\n    \"\"\"\n    if K.backend() == 'tensorflow':\n        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n    else:\n        return K.dot(x, kernel)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:33.302868Z","iopub.execute_input":"2022-12-09T07:24:33.303451Z","iopub.status.idle":"2022-12-09T07:24:33.323141Z","shell.execute_reply.started":"2022-12-09T07:24:33.303169Z","shell.execute_reply":"2022-12-09T07:24:33.322311Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"markdown","source":"Some Useful Variables  \n","metadata":{}},{"cell_type":"code","source":"#Tokenization and Padding\nvocab_size = 60000\nmaxlen = 250\nencode_dim = 20\nbatch_size = 32\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(X_train_final)\ntokenized_word_list = tokenizer.texts_to_sequences(X_train_final)\nX_train_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:33.324775Z","iopub.execute_input":"2022-12-09T07:24:33.325226Z","iopub.status.idle":"2022-12-09T07:24:55.700735Z","shell.execute_reply.started":"2022-12-09T07:24:33.325052Z","shell.execute_reply":"2022-12-09T07:24:55.699779Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"# tokenizer.word_index","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:55.702114Z","iopub.execute_input":"2022-12-09T07:24:55.702443Z","iopub.status.idle":"2022-12-09T07:24:55.706579Z","shell.execute_reply.started":"2022-12-09T07:24:55.702365Z","shell.execute_reply":"2022-12-09T07:24:55.705555Z"},"trusted":true},"execution_count":61,"outputs":[]},{"cell_type":"code","source":"print(np.shape(X_train_padded))\nprint(np.shape(X_train_final))","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:55.708197Z","iopub.execute_input":"2022-12-09T07:24:55.708683Z","iopub.status.idle":"2022-12-09T07:24:58.247665Z","shell.execute_reply.started":"2022-12-09T07:24:55.708487Z","shell.execute_reply":"2022-12-09T07:24:58.246851Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"(118140, 250)\n(118140,)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**EarlyStopping**  \nIt can be used to prevent overfitting.It basically waits a few epochs (5), monitoring the loss for the validation dataset.If the loss doesn't decrease for 2 epochs, it stops the training process.\n\n**ModelCheckpoint**  \nIt is used for saving the best model during training. After each epoch, it takes a look at the Validation accuracy, if it improves globally, this is the best model we have seen till now during the training process and hence, saves it.","metadata":{}},{"cell_type":"code","source":"#EarlyStopping and ModelCheckpoint\n\nes = EarlyStopping(monitor = 'val_loss', mode = 'min', verbose = 1, patience = 5)\n# es = EarlyStopping(monitor = 'val_loss', patience = 6)\nmc = ModelCheckpoint('model_best.h5', monitor = 'val_acc', mode = 'max', verbose = 1, save_best_only = True)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:58.249059Z","iopub.execute_input":"2022-12-09T07:24:58.249550Z","iopub.status.idle":"2022-12-09T07:24:58.258491Z","shell.execute_reply.started":"2022-12-09T07:24:58.249496Z","shell.execute_reply":"2022-12-09T07:24:58.257860Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"### Building the Model\n***\nThe model used comprises of BiDirectional LSTM with Attention layer on top of it, followed by a dense layer and finally a dense layer with sigmoid activation function to get the sentiment or the class.  \nOptimiser used is ADAM","metadata":{}},{"cell_type":"code","source":"#Building the model\nmodel = Sequential()\nembed = Embedding(input_dim = vocab_size, output_dim = 20, input_length = X_train_padded.shape[1], dropout = 0.4) \nmodel.add(embed)\nmodel.add(Bidirectional(CuDNNLSTM(200, return_sequences = True)))\n\nmodel.add(Dropout(0.3))\nmodel.add(AttentionWithContext())\nmodel.add(Dropout(0.5))\nmodel.add(Dense(512))\n# model.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(256))\n# model.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(128))\nmodel.add(LeakyReLU(alpha=0.2))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = [\"accuracy\"])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:24:58.260241Z","iopub.execute_input":"2022-12-09T07:24:58.260714Z","iopub.status.idle":"2022-12-09T07:25:00.744910Z","shell.execute_reply.started":"2022-12-09T07:24:58.260520Z","shell.execute_reply":"2022-12-09T07:25:00.744165Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding_1 (Embedding)      (None, 250, 20)           1200000   \n_________________________________________________________________\nbidirectional_1 (Bidirection (None, 250, 400)          355200    \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 250, 400)          0         \n_________________________________________________________________\nattention_with_context_1 (At (None, 400)               160800    \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 400)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 512)               205312    \n_________________________________________________________________\ndense_2 (Dense)              (None, 256)               131328    \n_________________________________________________________________\ndense_3 (Dense)              (None, 128)               32896     \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 128)               0         \n_________________________________________________________________\ndense_4 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 2,085,665\nTrainable params: 2,085,665\nNon-trainable params: 0\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Training\n***\nSplitting the Training set into Training set and Validation set","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_final2, X_val, y_train_final2, y_val = train_test_split(X_train_padded, y_train, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:25:00.748417Z","iopub.execute_input":"2022-12-09T07:25:00.748660Z","iopub.status.idle":"2022-12-09T07:25:00.877987Z","shell.execute_reply.started":"2022-12-09T07:25:00.748613Z","shell.execute_reply":"2022-12-09T07:25:00.877092Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"markdown","source":"Training the model","metadata":{}},{"cell_type":"code","source":"#Fitting the model\nmodel.fit(X_train_final2, y_train_final2, epochs = 50, batch_size = batch_size, verbose = 1, validation_data = [X_val, y_val], callbacks = [es, mc])\n\n# model.fit(X_train_final2, y_train_final2, epochs = 13, batch_size = batch_size, verbose = 1, validation_data = [X_val, y_val])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T07:25:00.879444Z","iopub.execute_input":"2022-12-09T07:25:00.879743Z","iopub.status.idle":"2022-12-09T08:15:09.537918Z","shell.execute_reply.started":"2022-12-09T07:25:00.879688Z","shell.execute_reply":"2022-12-09T08:15:09.537027Z"},"trusted":true},"execution_count":66,"outputs":[{"name":"stdout","text":"Train on 94512 samples, validate on 23628 samples\nEpoch 1/50\n94512/94512 [==============================] - 385s 4ms/step - loss: 0.3427 - acc: 0.8572 - val_loss: 0.3203 - val_acc: 0.8750\n\nEpoch 00001: val_acc improved from -inf to 0.87502, saving model to model_best.h5\nEpoch 2/50\n94512/94512 [==============================] - 375s 4ms/step - loss: 0.2741 - acc: 0.8930 - val_loss: 0.2876 - val_acc: 0.8897\n\nEpoch 00002: val_acc improved from 0.87502 to 0.88966, saving model to model_best.h5\nEpoch 3/50\n94512/94512 [==============================] - 376s 4ms/step - loss: 0.2459 - acc: 0.9048 - val_loss: 0.2671 - val_acc: 0.8949\n\nEpoch 00003: val_acc improved from 0.88966 to 0.89487, saving model to model_best.h5\nEpoch 4/50\n94512/94512 [==============================] - 376s 4ms/step - loss: 0.2200 - acc: 0.9150 - val_loss: 0.2719 - val_acc: 0.8941\n\nEpoch 00004: val_acc did not improve from 0.89487\nEpoch 5/50\n94512/94512 [==============================] - 375s 4ms/step - loss: 0.1988 - acc: 0.9224 - val_loss: 0.2811 - val_acc: 0.8896\n\nEpoch 00005: val_acc did not improve from 0.89487\nEpoch 6/50\n94512/94512 [==============================] - 374s 4ms/step - loss: 0.1792 - acc: 0.9298 - val_loss: 0.2752 - val_acc: 0.8933\n\nEpoch 00006: val_acc did not improve from 0.89487\nEpoch 7/50\n94512/94512 [==============================] - 373s 4ms/step - loss: 0.1624 - acc: 0.9355 - val_loss: 0.3135 - val_acc: 0.8914\n\nEpoch 00007: val_acc did not improve from 0.89487\nEpoch 8/50\n94512/94512 [==============================] - 374s 4ms/step - loss: 0.1468 - acc: 0.9417 - val_loss: 0.3126 - val_acc: 0.8924\n\nEpoch 00008: val_acc did not improve from 0.89487\nEpoch 00008: early stopping\n","output_type":"stream"},{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7fd4da6051d0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Testing\n***\nConverting the test data into sequences of integers and padding them.  \nLoading the best model and calculating the accuracy","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\ndata_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\n# data_test = data_test.dropna()\n# data_test = data_test.reset_index(drop=True)\nX_test = data_test['input'].values\n\ndef clean_text_test(X):\n    processed = []\n    for text in X:\n        text = normalize_text(str(text))\n        text = list(tf.keras.preprocessing.text.text_to_word_sequence(str(text)))\n        text = \" \".join(text)\n        input_text_pre_no_accent = str(ViUtils.remove_accents(text).decode(\"utf-8\"))\n        input_text_pre_accent = ViTokenizer.tokenize(text)\n        processed.append(input_text_pre_accent)\n    return processed\n\nX_test_final = clean_text_test(X_test)\n\ntokenized_word_list = tokenizer.texts_to_sequences(X_test_final)\nX_test_padded = pad_sequences(tokenized_word_list, maxlen = maxlen, padding='post')\n","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:09.539467Z","iopub.execute_input":"2022-12-09T08:15:09.539766Z","iopub.status.idle":"2022-12-09T08:15:29.411335Z","shell.execute_reply.started":"2022-12-09T08:15:09.539718Z","shell.execute_reply":"2022-12-09T08:15:29.410403Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"X_test_final[32]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.416321Z","iopub.execute_input":"2022-12-09T08:15:29.416590Z","iopub.status.idle":"2022-12-09T08:15:29.422915Z","shell.execute_reply.started":"2022-12-09T08:15:29.416543Z","shell.execute_reply":"2022-12-09T08:15:29.422118Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"'quán bé nhưng vô_cùng đắt hàng nha_tệ'"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_test_final[9])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.424697Z","iopub.execute_input":"2022-12-09T08:15:29.425332Z","iopub.status.idle":"2022-12-09T08:15:29.433130Z","shell.execute_reply.started":"2022-12-09T08:15:29.425281Z","shell.execute_reply":"2022-12-09T08:15:29.432143Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"quá trưa định đi thử phở thìn ở lò_đúc cơ nhưng mà đường xa mỏi gối thế quái nào lại sà vào cái quán này gà tần 55k không nhớ 55k hay 65k gì đấy thêm mì gói trần nước sôi 10k được cái là gà_ác nhưng tần rất ít vị thuốc ngải_cứu cũng chỉ được 1 tẹo nước cũng chỉ được 1 tí có_lẽ vì con gà đã chiếm hết diện_tích ống_bơ gà đã tần sẵn để trong ống_bơ khách gọi mới trần lại cho âm_ấm xong đổ ra bát 1 đống trông rất mất cảm_tình cá_nhân mình thấy vị dở vô_cùng dở ngon tệ ngon ngon tệ tệ\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_train[3551])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.434763Z","iopub.execute_input":"2022-12-09T08:15:29.435270Z","iopub.status.idle":"2022-12-09T08:15:29.441910Z","shell.execute_reply.started":"2022-12-09T08:15:29.435091Z","shell.execute_reply":"2022-12-09T08:15:29.440793Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"Thơm, sạch sẽ\n","output_type":"stream"}]},{"cell_type":"code","source":"print(y_train[3551])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.443393Z","iopub.execute_input":"2022-12-09T08:15:29.443975Z","iopub.status.idle":"2022-12-09T08:15:29.451609Z","shell.execute_reply.started":"2022-12-09T08:15:29.443634Z","shell.execute_reply":"2022-12-09T08:15:29.450309Z"},"trusted":true},"execution_count":71,"outputs":[{"name":"stdout","text":"1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[12])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.453106Z","iopub.execute_input":"2022-12-09T08:15:29.453746Z","iopub.status.idle":"2022-12-09T08:15:29.460249Z","shell.execute_reply.started":"2022-12-09T08:15:29.453353Z","shell.execute_reply":"2022-12-09T08:15:29.459340Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"tôi vừa đặt 1 xuất cơm vịt mất 70 trên now nhưng cửa_hàng lại quên không cho vịt vào\n","output_type":"stream"}]},{"cell_type":"code","source":"print(X_test_final[391])","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.461877Z","iopub.execute_input":"2022-12-09T08:15:29.462417Z","iopub.status.idle":"2022-12-09T08:15:29.470123Z","shell.execute_reply.started":"2022-12-09T08:15:29.462149Z","shell.execute_reply":"2022-12-09T08:15:29.469090Z"},"trusted":true},"execution_count":73,"outputs":[{"name":"stdout","text":"ăn bánh_mì ở quán 3 4 lần rồi mà hnay mới review được ưu_điểm đầu_tiên phải kể đến là giá_cả rất ok 4k 1 cái so với mặt_bằng chung ở hn là hợp_lý rồi thứ hai là bánh ăn rất thơm mình thích ăn mềm mềm bạn mình lại thích ăn giòn nên toàn mua 5 nọ 5 kia pate ngon 1 cái bé bé xinh_xinh nên ăn_không ngán thứ 3 là cái xe bán bánh_mì màu rất đẹp ngon vì mình thích màu vàng nhìn từ xa cái thấy luôn nổi_bật thôi rồi nhân_viên bán hàng nhiệt_tình vui_tính rất hài_lòng vì dịch_vụ tại quán nói_chung rất ưng à còn có pate bán ngoài pate ngon dã_man cả nhà mình ai cũng khen suốt nên toàn đặt luôn 10 hộp ngon m n nên thử nhé ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon ngon tệ ngon ngon\n","output_type":"stream"}]},{"cell_type":"code","source":"# y_pred[12]","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.471659Z","iopub.execute_input":"2022-12-09T08:15:29.472226Z","iopub.status.idle":"2022-12-09T08:15:29.478188Z","shell.execute_reply.started":"2022-12-09T08:15:29.472049Z","shell.execute_reply":"2022-12-09T08:15:29.477200Z"},"trusted":true},"execution_count":74,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\n# from tensorflow import keras\nimport keras\n\nmodel = keras.models.load_model('/kaggle/working/model_best.h5', custom_objects={'AttentionWithContext': AttentionWithContext} )\ny_pred = model.predict(X_test_padded)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:29.479791Z","iopub.execute_input":"2022-12-09T08:15:29.480511Z","iopub.status.idle":"2022-12-09T08:15:37.303129Z","shell.execute_reply.started":"2022-12-09T08:15:29.480238Z","shell.execute_reply":"2022-12-09T08:15:37.302064Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"my_submission = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103), 'Rating': np.array(y_pred).reshape(5103)})\n# you could use any filename. We choose submission here\nmy_submission.to_csv('submission_0912_b.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:16:46.309427Z","iopub.execute_input":"2022-12-09T08:16:46.309786Z","iopub.status.idle":"2022-12-09T08:16:46.346665Z","shell.execute_reply.started":"2022-12-09T08:16:46.309741Z","shell.execute_reply":"2022-12-09T08:16:46.345938Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('/kaggle/input/int3405-sentiment-analysis-problem/test.csv')\n# data_test = pd.DataFrame({'input':df['Comment'],'id':df[\"RevId\"]})\n# # data_test = data_test.dropna()\n# # data_test = data_test.reset_index(drop=True)\n# X_test = data_test['input'].values","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:37.359916Z","iopub.execute_input":"2022-12-09T08:15:37.360403Z","iopub.status.idle":"2022-12-09T08:15:37.364129Z","shell.execute_reply.started":"2022-12-09T08:15:37.360350Z","shell.execute_reply":"2022-12-09T08:15:37.363286Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"code","source":"# my_test_data = pd.DataFrame({'RevId': np.array(df[\"RevId\"]).reshape(5103),'input':df['Comment'],  'Rating': np.array(y_pred).reshape(5103)})\n# my_test_data.to_excel('my_test_data_predicted.xlsx', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-12-09T08:15:37.365519Z","iopub.execute_input":"2022-12-09T08:15:37.366883Z","iopub.status.idle":"2022-12-09T08:15:37.373212Z","shell.execute_reply.started":"2022-12-09T08:15:37.365925Z","shell.execute_reply":"2022-12-09T08:15:37.372375Z"},"trusted":true},"execution_count":78,"outputs":[]}]}